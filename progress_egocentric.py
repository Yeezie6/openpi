#!/usr/bin/env python3
"""
å¤„ç† Egocentric-10K æ•°æ®é›†çš„ä¸“ç”¨è„šæœ¬
æ”¯æŒè§†é¢‘ç¼©æ”¾ã€è£å‰ªå’Œåˆ†å—å¤„ç†
"""
import os
import shutil
import json
from pathlib import Path
import subprocess
from concurrent.futures import ProcessPoolExecutor
import multiprocessing as mp
import math
import decord
import time
from tqdm import tqdm

mp.set_start_method('fork', force=True)
os.getcwd
def get_video_info(video_path):
    """Get video information (fps, frame count, duration)"""
    cmd = [
        "ffprobe", "-v", "quiet", "-print_format", "json", "-show_streams",
        str(video_path)
    ]
    
    try:
        vr = decord.VideoReader(str(video_path))
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        
        for stream in data['streams']:
            if stream['codec_type'] == 'video':
                fps = eval(stream['r_frame_rate'])
                duration = float(stream.get('duration', 0))
                frame_count = int(stream.get('nb_frames', 0))
                
                if frame_count == 0 and duration > 0:
                    frame_count = int(duration * fps)
                
                return fps, frame_count, duration
        
        raise ValueError("No video stream found")
    except Exception as e:
        print(f"Failed to get video info: {video_path} - {e}")
        return None, None, None

def process_single_video_scale(args):
    """Process single video scaling
    - If scale_factor is provided, scale both width and height by factor.
    - Else, scale short side to target size.
    """
    mp4_file, output_file, target_size, scale_factor, is_intermediate_step = args
    
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åˆç†ï¼Œè·³è¿‡
    if output_file.exists() and output_file.stat().st_size > 1000:
        return f"Skipped (exists): {output_file.name}"
    
    # æ„å»ºç¼©æ”¾æ»¤é•œ
    if scale_factor is not None and scale_factor > 0:
        video_filter = (
            f"scale='ceil(iw*{scale_factor}/2)*2':'ceil(ih*{scale_factor}/2)*2'"
        )
    else:
        # å°†çŸ­è¾¹ç¼©æ”¾åˆ° target_size
        video_filter = (
            f"scale=w='if(gte(iw,ih), ceil((iw*{target_size})/(ih*2))*2, {target_size})':"
            f"h='if(gte(iw,ih), {target_size}, ceil((ih*{target_size})/(iw*2))*2)'"
        )
    
    cmd = [
        "ffmpeg", "-y", "-nostdin",
        "-i", str(mp4_file),
        "-threads", "2",
        "-vf", video_filter,
        "-c:v", "libx264", "-crf", "20",
        "-c:a", "copy",
        str(output_file)
    ]
    
    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=600)
        if is_intermediate_step and mp4_file.exists():
            mp4_file.unlink()  # åˆ é™¤åŸè§†é¢‘æ–‡ä»¶ï¼ˆä»…ä¸­é—´è¿‡ç¨‹ï¼‰
        return f"Completed: {output_file.name}"
    except subprocess.TimeoutExpired:
        print(f"[SCALE TIMEOUT] {mp4_file.name}")
        return f"Timeout: {mp4_file.name}"
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        print(f"[SCALE ERROR] {mp4_file.name}: {error_msg[:200]}")
        return f"Error: {mp4_file.name} - {error_msg[:100]}"
    except Exception as e:
        print(f"[SCALE EXCEPTION] {mp4_file.name}: {str(e)}")
        return f"Exception: {mp4_file.name} - {str(e)}"

def scale_videos_parallel(source_dir, output_dir, target_size=512, scale_factor=None, max_workers=64, process_id=-1, process_total=1, max_videos=None, is_intermediate_step=False):
    """
    Scale videos to target resolution in parallel
    
    Args:
        source_dir: Source directory containing videos
        output_dir: Output directory for scaled videos
        target_size: Target size for short side
        max_workers: Number of parallel workers
        process_id: Process ID for distributed processing (-1 for single process)
        process_total: Total number of processes for distributed processing
        max_videos: Maximum number of videos to process (None for all)
        is_intermediate_step: Whether this is an intermediate step
    """
    if scale_factor is not None and scale_factor > 0:
        print(f"Starting parallel video scaling by factor={scale_factor}, using {max_workers} workers...")
    else:
        print(f"Starting parallel video scaling to short side={target_size}, using {max_workers} workers...")
    
    source_path = Path(source_dir)
    output_path = Path(output_dir)
    
    if not source_path.exists():
        print(f"Source directory {source_path} does not exist")
        return
    
    # Collect all video files to process
    tasks = []
    for mp4_file in source_path.rglob("*.mp4"):
        relative_path = mp4_file.relative_to(source_path)
        output_file = output_path / relative_path
        tasks.append((mp4_file, output_file, target_size, scale_factor, is_intermediate_step))
    
    tasks.sort(key=lambda x: x[0].name)
    
    if process_id >= 0:
        tasks = tasks[process_id::process_total]
        print(f"Process {process_id}/{process_total}: assigned {len(tasks)} videos")
    
    # Limit number of videos if specified
    if max_videos is not None and max_videos > 0:
        tasks = tasks[:max_videos]
        print(f"Limiting to first {max_videos} videos")
    
    print(f"Total video files to process: {len(tasks)}")
    
    if not tasks:
        print("No video files found")
        return
    
    # Process in parallel with progress bar
    completed = 0
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        with tqdm(total=len(tasks), desc="Scaling videos", unit="video") as pbar:
            for result in executor.map(process_single_video_scale, tasks):
                completed += 1
                pbar.set_postfix_str(result.split(':')[0] if ':' in result else result)
                pbar.update(1)

def process_single_video_resize_crop(args):
    """Process single video: resize short side and center crop"""
    mp4_file, output_file, short_side_size, crop_size, is_intermediate_step = args

    output_file.parent.mkdir(parents=True, exist_ok=True)

    # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åˆç†ï¼Œè·³è¿‡
    if output_file.exists() and output_file.stat().st_size > 1000:
        return f"Skipped (exists): {output_file.name}"
        
    video_filter = (
        f"crop={short_side_size}:{short_side_size}:(iw-{short_side_size})/2:(ih-{short_side_size})/2,"
        f"scale={crop_size}:{crop_size}"
    )
    cmd = [
        "ffmpeg", "-y", "-nostdin", "-loglevel", "error",
        "-i", str(mp4_file),
        "-threads", "2",
        "-vf", video_filter,
        "-r", "30",  # å¼ºåˆ¶è¾“å‡ºå¸§ç‡ä¸º30fps
        "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
        "-pix_fmt", "yuv420p",
        "-an",
        "-movflags", "+faststart",
        str(output_file)
    ]

    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=600)
        if is_intermediate_step and mp4_file.exists():
            mp4_file.unlink()  # åˆ é™¤åŸè§†é¢‘æ–‡ä»¶ï¼ˆä»…ä¸­é—´è¿‡ç¨‹ï¼‰
        return f"Completed: {output_file.name}"
    except subprocess.TimeoutExpired:
        print(f"[CROP TIMEOUT] {mp4_file.name}")
        return f"Timeout: {mp4_file.name}"
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        print(f"[CROP ERROR] {mp4_file.name}: {error_msg[:200]}")
        return f"Error: {mp4_file.name} - {error_msg[:100]}"
    except Exception as e:
        print(f"[CROP EXCEPTION] {mp4_file.name}: {str(e)}")
        return f"Exception: {mp4_file.name} - {str(e)}"

def process_single_video_crop_rect(args):
    """Process single video: center crop to given width and height (no scaling)"""
    mp4_file, output_file, crop_w, crop_h, is_intermediate_step = args

    output_file.parent.mkdir(parents=True, exist_ok=True)

    if output_file.exists() and output_file.stat().st_size > 1000:
        return f"Skipped (exists): {output_file.name}"

    # ä»…ä¸­å¿ƒè£å‰ªä¸ºæŒ‡å®šçŸ©å½¢å°ºå¯¸
    video_filter = f"crop={crop_w}:{crop_h}:(iw-{crop_w})/2:(ih-{crop_h})/2"

    cmd = [
        "ffmpeg", "-y", "-nostdin", "-loglevel", "error",
        "-i", str(mp4_file),
        "-threads", "2",
        "-vf", video_filter,
        "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
        "-pix_fmt", "yuv420p",
        "-an",
        "-movflags", "+faststart",
        str(output_file)
    ]

    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=600)
        if is_intermediate_step and mp4_file.exists():
            mp4_file.unlink()  # åˆ é™¤åŸè§†é¢‘æ–‡ä»¶ï¼ˆä»…ä¸­é—´è¿‡ç¨‹ï¼‰
        return f"Completed: {output_file.name}"
    except subprocess.TimeoutExpired:
        print(f"[CROP_RECT TIMEOUT] {mp4_file.name}")
        return f"Timeout: {mp4_file.name}"
    except subprocess.CalledProcessError as e:
        # è·å–è¾“å…¥è§†é¢‘å°ºå¯¸ç”¨äºé”™è¯¯ä¿¡æ¯
        try:
            probe_cmd = ["ffprobe", "-v", "error", "-select_streams", "v:0", 
                        "-show_entries", "stream=width,height", "-of", "csv=s=x:p=0", str(mp4_file)]
            size_result = subprocess.run(probe_cmd, capture_output=True, text=True)
            actual_size = size_result.stdout.strip()
            error_msg = f"input size {actual_size}, required {crop_w}x{crop_h}"
            print(f"[CROP_RECT ERROR] {mp4_file.name}: {error_msg}")
            return f"Error: {mp4_file.name} ({error_msg})"
        except:
            error_msg = e.stderr if e.stderr else str(e)
            print(f"[CROP_RECT ERROR] {mp4_file.name}: {error_msg[:200]}")
            return f"Error: {mp4_file.name} (crop {crop_w}x{crop_h} failed)"
    except Exception as e:
        print(f"[CROP_RECT EXCEPTION] {mp4_file.name}: {str(e)}")
        return f"Exception: {mp4_file.name} - {str(e)}"

def batch_resize_crop_videos(source_dir, output_dir, short_side_size=512, crop_size=256, max_workers=8, process_id=-1, process_total=1, max_videos=None, is_intermediate_step=False):
    """
    æ‰¹é‡å¤„ç†è§†é¢‘ï¼šå°†çŸ­è¾¹ç¼©æ”¾åˆ°æŒ‡å®šå°ºå¯¸ï¼Œç„¶åä¸­å¿ƒè£åˆ‡åˆ°æŒ‡å®šåˆ†è¾¨ç‡
    
    Args:
        source_dir: æºè§†é¢‘ç›®å½•
        output_dir: è¾“å‡ºè§†é¢‘ç›®å½•
        short_side_size: çŸ­è¾¹ç¼©æ”¾çš„ç›®æ ‡å°ºå¯¸
        crop_size: è£åˆ‡çš„ç›®æ ‡å°ºå¯¸ï¼ˆæ­£æ–¹å½¢ï¼‰
        max_workers: å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
        process_id: è¿›ç¨‹IDç”¨äºåˆ†å¸ƒå¼å¤„ç†
        process_total: æ€»è¿›ç¨‹æ•°
        max_videos: Maximum number of videos to process (None for all)
        is_intermediate_step: æ˜¯å¦ä¸ºä¸­é—´æ­¥éª¤
    """
    print(f"Starting batch video resize and crop...")
    print(f"Short side resize to: {short_side_size}")
    print(f"Center crop to: {crop_size}x{crop_size}")
    print(f"Using {max_workers} workers")

    source_path = Path(source_dir)
    output_path = Path(output_dir)

    if not source_path.exists():
        print(f"Source directory {source_path} does not exist")
        return

    # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„è§†é¢‘æ–‡ä»¶
    tasks = []
    for mp4_file in source_path.rglob("*.mp4"):
        if '/tmp/' in str(mp4_file):
            continue
        relative_path = mp4_file.relative_to(source_path)
        output_file = output_path / relative_path
        tasks.append((mp4_file, output_file, short_side_size, crop_size, is_intermediate_step))

    tasks.sort(key=lambda x: x[0].name)
    
    if process_id >= 0:
        tasks = tasks[process_id::process_total]
        print(f"Process {process_id}/{process_total}: assigned {len(tasks)} videos")
        
    # Limit number of videos if specified
    if max_videos is not None and max_videos > 0:
        tasks = tasks[:max_videos]
        print(f"Limiting to first {max_videos} videos")
        
    print(f"Total video files to process: {len(tasks)}")
    
    if not tasks:
        print("No video files found to process")
        return

    # å¹¶è¡Œå¤„ç† with progress bar
    completed = 0
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        with tqdm(total=len(tasks), desc="Resize & Crop videos", unit="video") as pbar:
            for result in executor.map(process_single_video_resize_crop, tasks):
                completed += 1
                pbar.set_postfix_str(result.split(':')[0] if ':' in result else result)
                pbar.update(1)

    print(f"\n=== Processing completed ===")
    print(f"Total processed: {completed}/{len(tasks)}")

def process_single_video_chunk_frames(args):
    """Process single video: chunk by frame count"""
    mp4_file, output_dir, frames_per_chunk, delete_original, is_intermediate_step = args
    
    try:
        # è·å–è§†é¢‘ä¿¡æ¯
        vr = decord.VideoReader(str(mp4_file))
        fps = vr.get_avg_fps()
        frame_count = len(vr)
        
        base_name = mp4_file.stem
        output_dir.mkdir(parents=True, exist_ok=True)
        
        num_chunks = math.ceil(frame_count / frames_per_chunk)
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰chunkéƒ½å·²å­˜åœ¨
        all_exist = True
        for chunk_id in range(num_chunks):
            output_chunk = output_dir / f"{base_name}_{chunk_id:04d}.mp4"
            if not output_chunk.exists() or output_chunk.stat().st_size == 0:
                all_exist = False
                break
        
        if all_exist:
            if delete_original and mp4_file.exists():
                mp4_file.unlink()
            return f"Skipped (all chunks exist): {mp4_file.name}"
        
        # é€ä¸ªç”Ÿæˆchunkï¼Œä½¿ç”¨ç²¾ç¡®çš„å¸§æå–
        for chunk_id in range(num_chunks):
            output_chunk = output_dir / f"{base_name}_{chunk_id:04d}.mp4"
            
            # å¦‚æœchunkå·²å­˜åœ¨ä¸”å¤§å°åˆç†ï¼Œè·³è¿‡
            if output_chunk.exists() and output_chunk.stat().st_size > 1000:
                continue
            
            start_frame = chunk_id * frames_per_chunk
            end_frame = min(start_frame + frames_per_chunk, frame_count)
            actual_frames = end_frame - start_frame
            
            # ä½¿ç”¨ -ss å’Œ -frames:v ç²¾ç¡®æå–å¸§
            start_time = start_frame / fps
            
            cmd = [
                "ffmpeg", "-y", "-nostdin", "-loglevel", "error",
                "-ss", str(start_time),  # ä»æŒ‡å®šæ—¶é—´å¼€å§‹
                "-i", str(mp4_file),
                "-frames:v", str(actual_frames),  # ç²¾ç¡®æå–å¸§æ•°
                "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
                "-pix_fmt", "yuv420p",
                "-c:a", "copy",
                "-movflags", "+faststart",
                str(output_chunk)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=300)
        
        if is_intermediate_step and delete_original and mp4_file.exists():
            mp4_file.unlink()  # åˆ é™¤åŸè§†é¢‘æ–‡ä»¶ï¼ˆä»…ä¸­é—´è¿‡ç¨‹ï¼‰
        
        return f"Completed: {mp4_file.name} -> {num_chunks} chunks"
        
    except subprocess.TimeoutExpired:
        print(f"[CHUNK TIMEOUT] {mp4_file.name}")
        return f"Timeout: {mp4_file.name}"
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        print(f"[CHUNK ERROR] {mp4_file.name}: {error_msg[:200]}")
        return f"Error: {mp4_file.name} - {error_msg[:100]}"
    except Exception as e:
        print(f"[CHUNK EXCEPTION] {mp4_file.name}: {str(e)}")
        return f"Exception: {mp4_file.name} - {str(e)}"

def chunk_videos_parallel(source_dir, output_dir, frames_per_chunk=300, max_workers=8, 
                         delete_original=False, process_id=-1, process_total=1, max_videos=None, is_intermediate_step=False):
    """
    Chunk videos in parallel by frame count
    
    Args:
        source_dir: Source directory containing videos
        output_dir: Output directory for chunked videos
        frames_per_chunk: Number of frames per chunk
        max_workers: Number of parallel workers
        delete_original: Whether to delete original videos after processing
        process_id: Process ID for distributed processing
        process_total: Total number of processes
        max_videos: Maximum number of videos to process (None for all)
        is_intermediate_step: Whether this is an intermediate step
    """
    print(f"Starting parallel video chunking...")
    print(f"Frames per chunk: {frames_per_chunk}")
    print(f"Using {max_workers} workers")
    print(f"Delete original: {delete_original}")

    source_path = Path(source_dir)
    output_path = Path(output_dir)
    
    if not source_path.exists():
        print(f"Source directory {source_path} does not exist")
        return
    
    # Collect all video files to process
    tasks = []
    for mp4_file in source_path.rglob("*.mp4"):
        relative_path = mp4_file.relative_to(source_path)
        output_subdir = output_path / relative_path.parent
        tasks.append((mp4_file, output_subdir, frames_per_chunk, delete_original, is_intermediate_step))
    
    tasks.sort(key=lambda x: x[0].name)
    
    if process_id >= 0:
        tasks = tasks[process_id::process_total]
        print(f"Process {process_id}/{process_total}: assigned {len(tasks)} videos")
        
    # Limit number of videos if specified
    if max_videos is not None and max_videos > 0:
        tasks = tasks[:max_videos]
        print(f"Limiting to first {max_videos} videos")
        
    print(f"Total video files to process: {len(tasks)}")
    
    if not tasks:
        print("No video files found to process")
        return
    
    # Process all tasks with progress bar
    completed = 0
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        with tqdm(total=len(tasks), desc="Chunking videos", unit="video") as pbar:
            for result in executor.map(process_single_video_chunk_frames, tasks):
                completed += 1
                pbar.set_postfix_str(result.split(':')[0] if ':' in result else result)
                pbar.update(1)
    
    print(f"\n=== Chunking completed ===")
    print(f"Total processed: {completed}/{len(tasks)}")

def process_single_video_enhance(args):
    """Process single video: enhance clarity with denoising and sharpening"""
    mp4_file, output_file, enhance_params, is_intermediate_step = args
    
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åˆç†ï¼Œè·³è¿‡
    if output_file.exists() and output_file.stat().st_size > 1000:
        return f"Skipped (exists): {output_file.name}"
    
    # æ„å»ºè§†é¢‘æ»¤é•œï¼šå»å™ª + é”åŒ– + å¯¹æ¯”åº¦å¢å¼º
    filters = []
    
    # 1. å»å™ªï¼ˆå¯é€‰ï¼‰
    if enhance_params.get('denoise', True):
        denoise_strength = enhance_params.get('denoise_strength', 'medium')
        if denoise_strength == 'light':
            filters.append("hqdn3d=2:1.5:3:2.25")
        elif denoise_strength == 'medium':
            filters.append("hqdn3d=4:3:6:4.5")
        elif denoise_strength == 'strong':
            filters.append("hqdn3d=8:6:12:9")
    
    # 2. é”åŒ–
    if enhance_params.get('sharpen', True):
        sharpen_strength = enhance_params.get('sharpen_strength', 'medium')
        if sharpen_strength == 'light':
            filters.append("unsharp=5:5:0.5:5:5:0.0")
        elif sharpen_strength == 'medium':
            filters.append("unsharp=5:5:1.0:5:5:0.0")
        elif sharpen_strength == 'strong':
            filters.append("unsharp=5:5:1.5:5:5:0.0")
    
    # 3. å¯¹æ¯”åº¦å’Œé¥±å’Œåº¦å¢å¼ºï¼ˆå¯é€‰ï¼‰
    if enhance_params.get('contrast', False):
        contrast_value = enhance_params.get('contrast_value', 1.1)
        brightness = enhance_params.get('brightness', 0.0)
        saturation = enhance_params.get('saturation', 1.0)
        filters.append(f"eq=contrast={contrast_value}:brightness={brightness}:saturation={saturation}")
    
    video_filter = ",".join(filters) if filters else "copy"
    
    cmd = [
        "ffmpeg", "-y", "-nostdin", "-loglevel", "error",
        "-i", str(mp4_file),
        "-threads", "2",
        "-vf", video_filter,
        "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
        "-pix_fmt", "yuv420p",
        "-c:a", "copy",
        "-movflags", "+faststart",
        str(output_file)
    ]
    
    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=600)
        if is_intermediate_step and mp4_file.exists():
            mp4_file.unlink()  # åˆ é™¤åŸè§†é¢‘æ–‡ä»¶ï¼ˆä»…ä¸­é—´è¿‡ç¨‹ï¼‰
        return f"Completed: {output_file.name}"
    except subprocess.TimeoutExpired:
        print(f"[ENHANCE TIMEOUT] {mp4_file.name}")
        return f"Timeout: {mp4_file.name}"
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        print(f"[ENHANCE ERROR] {mp4_file.name}: {error_msg[:200]}")
        return f"Error: {mp4_file.name} - {error_msg[:100]}"
    except Exception as e:
        print(f"[ENHANCE EXCEPTION] {mp4_file.name}: {str(e)}")
        return f"Exception: {mp4_file.name} - {str(e)}"

def enhance_videos_parallel(source_dir, output_dir, max_workers=8, enhance_params=None,
                           process_id=-1, process_total=1, max_videos=None, is_intermediate_step=False):
    """
    Enhance video clarity with denoising and sharpening in parallel
    
    Args:
        source_dir: Source directory containing videos
        output_dir: Output directory for enhanced videos
        max_workers: Number of parallel workers
        enhance_params: Dictionary of enhancement parameters
        process_id: Process ID for distributed processing
        process_total: Total number of processes
        max_videos: Maximum number of videos to process (None for all)
        is_intermediate_step: Whether this is an intermediate step
    """
    if enhance_params is None:
        enhance_params = {
            'denoise': True,
            'denoise_strength': 'medium',  # light, medium, strong
            'sharpen': True,
            'sharpen_strength': 'medium',  # light, medium, strong
            'contrast': False,
            'contrast_value': 1.1,
            'brightness': 0.0,
            'saturation': 1.0
        }
    
    print(f"Starting video enhancement, using {max_workers} workers...")
    print(f"Enhancement parameters: denoise={enhance_params['denoise']}, sharpen={enhance_params['sharpen']}")
    
    source_path = Path(source_dir)
    output_path = Path(output_dir)
    
    if not source_path.exists():
        print(f"Source directory {source_path} does not exist")
        return
    
    # Collect all video files to process
    tasks = []
    for mp4_file in source_path.rglob("*.mp4"):
        relative_path = mp4_file.relative_to(source_path)
        output_file = output_path / relative_path
        tasks.append((mp4_file, output_file, enhance_params, is_intermediate_step))
    
    tasks.sort(key=lambda x: x[0].name)
    
    if process_id >= 0:
        tasks = tasks[process_id::process_total]
        print(f"Process {process_id}/{process_total}: assigned {len(tasks)} videos")
    
    if max_videos is not None and max_videos > 0:
        tasks = tasks[:max_videos]
        print(f"Limiting to first {max_videos} videos")
    
    print(f"Total videos to enhance: {len(tasks)}")
    
    if not tasks:
        print("No videos found to enhance")
        return
    
    # Process all tasks with progress bar
    completed = 0
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        with tqdm(total=len(tasks), desc="Enhancing videos", unit="video") as pbar:
            for result in executor.map(process_single_video_enhance, tasks):
                completed += 1
                pbar.set_postfix_str(result.split(':')[0] if ':' in result else result)
                pbar.update(1)
    
    print(f"\n=== Enhancement completed ===")
    print(f"Total processed: {completed}/{len(tasks)}")

def process_single_video_fisheye(args):
    """Process single video: fisheye to rectilinear projection"""
    input_video, output_video, fisheye_params, is_intermediate_step = args
    
    try:
        output_video.parent.mkdir(parents=True, exist_ok=True)
        
        # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åˆç†ï¼Œè·³è¿‡
        if output_video.exists() and output_video.stat().st_size > 1000:
            return f"Skipped (exists): {output_video.name}"
        
        cmd = [
            "ffmpeg", "-y", "-nostdin", "-loglevel", "error",
            "-i", str(input_video),
            "-vf", f"v360=fisheye:rectilinear:ih_fov={fisheye_params['ih_fov']}:iv_fov={fisheye_params['iv_fov']}:h_fov={fisheye_params['h_fov']}:v_fov={fisheye_params['v_fov']}:w={fisheye_params['w']}:h={fisheye_params['h']}:interp={fisheye_params['interp']}",
            "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
            "-an",
            "-threads", "4",  # å¢åŠ çº¿ç¨‹æ•°ä»¥åŠ å¿«å¤„ç†
            str(output_video)
        ]
        
        result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=1800)  # å¢åŠ åˆ°30åˆ†é’Ÿè¶…æ—¶
        if is_intermediate_step and input_video.exists():
            input_video.unlink()  # åˆ é™¤åŸè§†é¢‘æ–‡ä»¶ï¼ˆä»…ä¸­é—´è¿‡ç¨‹ï¼‰
        return f"Completed fisheye conversion: {output_video.name}"
        
    except subprocess.TimeoutExpired:
        print(f"[FISHEYE TIMEOUT] {input_video.name}")
        return f"Timeout: {input_video.name}"
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr if e.stderr else str(e)
        print(f"[FISHEYE ERROR] {input_video.name}: {error_msg[:200]}")
        return f"Error: {input_video.name} - {error_msg[:100]}"
    except Exception as e:
        print(f"[FISHEYE EXCEPTION] {input_video.name}: {str(e)}")
        return f"Exception: {input_video.name} - {str(e)}"

def process_fisheye_videos(source_dir, output_dir, max_workers=32, fisheye_params=None, 
                          process_id=-1, process_total=1, max_videos=None, is_intermediate_step=False):
    """
    Process fisheye to rectilinear projection for videos in parallel
    
    Args:
        source_dir: Source directory containing fisheye videos
        output_dir: Output directory for converted videos
        max_workers: Number of parallel workers
        fisheye_params: Dictionary of fisheye conversion parameters
        process_id: Process ID for distributed processing
        process_total: Total number of processes
        max_videos: Maximum number of videos to process (None for all)
        is_intermediate_step: Whether this is an intermediate step
    """
    if fisheye_params is None:
        fisheye_params = {
            'ih_fov': 110,      # Input horizontal field of view
            'iv_fov': 110,      # Input vertical field of view
            'h_fov': 90,        # Output horizontal field of view
            'v_fov': 90,        # Output vertical field of view
            'w': 1408,          # Output width
            'h': 1408,          # Output height
            'interp': 'lanczos' # Interpolation method
        }
    
    print(f"Starting fisheye conversion, using {max_workers} workers...")
    print(f"Fisheye parameters: {fisheye_params}")
    
    source_path = Path(source_dir)
    output_path = Path(output_dir)
    
    if not source_path.exists():
        print(f"Source directory {source_path} does not exist")
        return
    
    # Collect all video files to process
    tasks = []
    for mp4_file in source_path.rglob("*.mp4"):
        relative_path = mp4_file.relative_to(source_path)
        output_file = output_path / relative_path
        tasks.append((mp4_file, output_file, fisheye_params, is_intermediate_step))
    
    tasks.sort(key=lambda x: x[0].name)
    
    if process_id >= 0:
        tasks = tasks[process_id::process_total]
        print(f"Process {process_id}/{process_total}: assigned {len(tasks)} videos")
    
    # Limit number of videos if specified
    if max_videos is not None and max_videos > 0:
        tasks = tasks[:max_videos]
        print(f"Limiting to first {max_videos} videos")
    
    print(f"Total fisheye videos to process: {len(tasks)}")
    
    if not tasks:
        print("No fisheye videos found to process")
        return
    
    # Process all tasks with progress bar
    completed = 0
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        with tqdm(total=len(tasks), desc="Fisheye conversion", unit="video") as pbar:
            for result in executor.map(process_single_video_fisheye, tasks):
                completed += 1
                pbar.set_postfix_str(result.split(':')[0] if ':' in result else result)
                pbar.update(1)
    
    print(f"\n=== Fisheye conversion completed ===")
    print(f"Total processed: {completed}/{len(tasks)}")

def main():
    import argparse
    parser = argparse.ArgumentParser(
        description="å¤„ç† Egocentric-10K è§†é¢‘æ•°æ®é›†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
å¤„ç†æ¨¡å¼:
  scale:   ç¼©æ”¾è§†é¢‘çŸ­è¾¹åˆ°æŒ‡å®šå°ºå¯¸
  crop:    å…ˆç¼©æ”¾åä¸­å¿ƒè£å‰ªåˆ°æ­£æ–¹å½¢
  chunk:   æŒ‰å¸§æ•°åˆ†å—è§†é¢‘
  fisheye: é±¼çœ¼é•œå¤´è½¬æ¢ä¸ºçŸ©å½¢æŠ•å½±
  enhance: è§†é¢‘å¢å¼ºï¼ˆå»å™ª+é”åŒ–+å¯¹æ¯”åº¦ï¼‰
  
å¯ä»¥æŒ‡å®šå¤šä¸ªæ¨¡å¼ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ï¼Œä¾‹å¦‚: --mode enhance,fisheye,scale,chunk
  
ç¤ºä¾‹:
  # å•ä¸ªæ¨¡å¼ï¼šè§†é¢‘å¢å¼ºï¼ˆå»å™ª+é”åŒ–ï¼‰
  python process_egocentric.py --mode enhance --source /disk0/videos --output /disk0/enhanced --workers 16
  
  # è§†é¢‘å¢å¼ºï¼ˆå¼ºåŠ›é”åŒ–+å¯¹æ¯”åº¦å¢å¼ºï¼‰
  python process_egocentric.py --mode enhance --source /disk0/videos --output /disk0/enhanced --sharpen-strength strong --enhance-contrast --contrast-value 1.15
  
  # å•ä¸ªæ¨¡å¼ï¼šç¼©æ”¾è§†é¢‘çŸ­è¾¹åˆ°512
  python process_egocentric.py --mode scale --source /disk0/videos --output /disk0/output --target-size 512 --workers 32
  
  # å•ä¸ªæ¨¡å¼ï¼šä¸­å¿ƒè£å‰ªåˆ°256x256
  python process_egocentric.py --mode crop --source /disk0/videos --output /disk0/output --short-side 512 --crop-size 256 --workers 16
  
  # å•ä¸ªæ¨¡å¼ï¼šåˆ†å—è§†é¢‘ï¼ˆæ¯300å¸§ï¼‰
  python process_egocentric.py --mode chunk --source /disk0/videos --output /disk0/output --frames-per-chunk 300 --workers 8 --delete-original
  
  # å•ä¸ªæ¨¡å¼ï¼šé±¼çœ¼é•œå¤´è½¬æ¢
  python process_egocentric.py --mode fisheye --source /disk0/Egocentric-10K/factory_002 --output /share/HaWoR/example/render --workers 24 --ih-fov 110 --h-fov 90 --output-width 512 --output-height 512
  
  # æµæ°´çº¿æ¨¡å¼ï¼šé±¼çœ¼è½¬æ¢ -> ç¼©æ”¾ -> åˆ†å—
  python process_egocentric.py --mode fisheye,scale,chunk --source /disk0/fisheye_videos --output /disk0/final_output --target-size 512 --frames-per-chunk 300 --workers 16
  
  # æµæ°´çº¿æ¨¡å¼ï¼šç¼©æ”¾ -> è£å‰ª
  python process_egocentric.py --mode scale,crop --source /disk0/videos --output /disk0/cropped --target-size 512 --crop-size 256 --workers 32
  
  # ä¿ç•™ä¸­é—´ç»“æœï¼šå…ˆchunkåcropï¼ˆä¿ç•™910Ã—512çš„åˆ†å—è§†é¢‘ï¼‰
  python process_egocentric.py --mode fisheye,scale,chunk,crop --source example/exp/raw --output example/exp/test --target-size 512 --crop-size 256 --frames-per-chunk 300 --keep-intermediate --workers 16
  
  # ä»…ä¿ç•™chunkåçš„ç»“æœï¼ˆåˆ é™¤fisheyeå’Œscaleçš„ä¸­é—´æ–‡ä»¶ï¼Œä¿ç•™chunkåçš„910Ã—512è§†é¢‘å’Œæœ€ç»ˆ256Ã—256è§†é¢‘ï¼‰
  python process_egocentric.py --mode fisheye,scale,chunk,crop --source example/exp/raw --output example/exp/test --ih-fov 105 --iv-fov 95 --h-fov 95 --v-fov 90 --output-width 910 --output-height 512 --target-size 512 --crop-size 256 --frames-per-chunk 300 --keep-chunked --workers 16
        """
    )
    
    parser.add_argument('--mode', required=True, type=str,
                       help='å¤„ç†æ¨¡å¼ï¼Œå¯ä»¥æ˜¯å•ä¸ªæ¨¡å¼æˆ–é€—å·åˆ†éš”çš„å¤šä¸ªæ¨¡å¼ (fisheye,scale,crop,chunk)')
    parser.add_argument('--source', required=True,
                       help='æºè§†é¢‘ç›®å½•')
    parser.add_argument('--output', required=True,
                       help='è¾“å‡ºç›®å½•')
    
    # Scale mode arguments
    parser.add_argument('--target-size', type=int, default=512,
                       help='ç¼©æ”¾ç›®æ ‡å°ºå¯¸ï¼ˆçŸ­è¾¹ï¼‰ï¼ˆé»˜è®¤: 512ï¼‰')
    parser.add_argument('--scale-factor', type=float, default=None,
                       help='æŒ‰æ¯”ä¾‹ç¼©æ”¾å› å­ï¼ˆå®½é«˜åŒæ—¶æŒ‰æ­¤å› å­ç¼©æ”¾ï¼Œä¾‹å¦‚ 1.46ï¼‰')
    
    # Crop mode arguments
    parser.add_argument('--short-side', type=int, default=512,
                       help='è£å‰ªå‰çŸ­è¾¹å°ºå¯¸ï¼ˆé»˜è®¤: 512ï¼‰')
    parser.add_argument('--crop-size', type=int, default=256,
                       help='è£å‰ªåæ­£æ–¹å½¢å°ºå¯¸ï¼ˆé»˜è®¤: 256ï¼‰')
    parser.add_argument('--crop-width', type=int, default=None,
                       help='çŸ©å½¢ä¸­å¿ƒè£å‰ªå®½åº¦ï¼ˆä¸ crop-height ä¸€èµ·ä½¿ç”¨ï¼‰')
    parser.add_argument('--crop-height', type=int, default=None,
                       help='çŸ©å½¢ä¸­å¿ƒè£å‰ªé«˜åº¦ï¼ˆä¸ crop-width ä¸€èµ·ä½¿ç”¨ï¼‰')
    
    # Chunk mode arguments
    parser.add_argument('--frames-per-chunk', type=int, default=300,
                       help='æ¯ä¸ªåˆ†å—çš„å¸§æ•°ï¼ˆé»˜è®¤: 300ï¼‰')
    parser.add_argument('--delete-original', action='store_true',
                       help='åˆ†å—ååˆ é™¤åŸå§‹è§†é¢‘')
    
    # Fisheye mode arguments
    parser.add_argument('--ih-fov', type=int, default=95,
                       help='è¾“å…¥æ°´å¹³è§†åœºè§’')
    parser.add_argument('--iv-fov', type=int, default=95,
                       help='è¾“å…¥å‚ç›´è§†åœºè§’')
    parser.add_argument('--h-fov', type=int, default=70,
                       help='è¾“å‡ºæ°´å¹³è§†åœºè§’')
    parser.add_argument('--v-fov', type=int, default=70,
                       help='è¾“å‡ºå‚ç›´è§†åœºè§’')
    parser.add_argument('--output-width', type=int, default=1024,
                       help='è¾“å‡ºè§†é¢‘å®½åº¦ï¼ˆé»˜è®¤: 512ï¼‰')
    parser.add_argument('--output-height', type=int, default=1024,
                       help='è¾“å‡ºè§†é¢‘é«˜åº¦ï¼ˆé»˜è®¤: 512ï¼‰')
    parser.add_argument('--interp', type=str, default='lanczos',
                       choices=['lanczos', 'cubic', 'linear'],
                       help='æ’å€¼æ–¹æ³•ï¼ˆé»˜è®¤: cubicï¼‰')
    
    # Enhance mode arguments
    parser.add_argument('--denoise', action='store_true', default=True,
                       help='å¯ç”¨å»å™ªï¼ˆé»˜è®¤: Trueï¼‰')
    parser.add_argument('--no-denoise', dest='denoise', action='store_false',
                       help='ç¦ç”¨å»å™ª')
    parser.add_argument('--denoise-strength', type=str, default='medium',
                       choices=['light', 'medium', 'strong'],
                       help='å»å™ªå¼ºåº¦ï¼ˆé»˜è®¤: mediumï¼‰')
    parser.add_argument('--sharpen', action='store_true', default=True,
                       help='å¯ç”¨é”åŒ–ï¼ˆé»˜è®¤: Trueï¼‰')
    parser.add_argument('--no-sharpen', dest='sharpen', action='store_false',
                       help='ç¦ç”¨é”åŒ–')
    parser.add_argument('--sharpen-strength', type=str, default='medium',
                       choices=['light', 'medium', 'strong'],
                       help='é”åŒ–å¼ºåº¦ï¼ˆé»˜è®¤: mediumï¼‰')
    parser.add_argument('--enhance-contrast', action='store_true',
                       help='å¯ç”¨å¯¹æ¯”åº¦å¢å¼º')
    parser.add_argument('--contrast-value', type=float, default=1.1,
                       help='å¯¹æ¯”åº¦å€¼ï¼ˆé»˜è®¤: 1.1ï¼‰')
    parser.add_argument('--brightness', type=float, default=0.0,
                       help='äº®åº¦è°ƒæ•´ï¼ˆé»˜è®¤: 0.0ï¼‰')
    parser.add_argument('--saturation', type=float, default=1.0,
                       help='é¥±å’Œåº¦ï¼ˆé»˜è®¤: 1.0ï¼‰')
    
    # Common arguments
    parser.add_argument('--workers', type=int, default=8,
                       help='å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 8ï¼‰')
    parser.add_argument('--process-id', type=int, default=-1,
                       help='åˆ†å¸ƒå¼å¤„ç†çš„è¿›ç¨‹IDï¼ˆ-1è¡¨ç¤ºå•è¿›ç¨‹ï¼‰')
    parser.add_argument('--process-total', type=int, default=1,
                       help='åˆ†å¸ƒå¼å¤„ç†çš„æ€»è¿›ç¨‹æ•°')
    parser.add_argument('--max-videos', type=int, default=None,
                       help='é™åˆ¶å¤„ç†çš„è§†é¢‘æ•°é‡ï¼ˆé»˜è®¤: å¤„ç†æ‰€æœ‰è§†é¢‘ï¼‰')
    parser.add_argument('--keep-intermediate', action='store_true',
                       help='ä¿ç•™ä¸­é—´ä¸´æ—¶æ–‡ä»¶ï¼ˆä¸è‡ªåŠ¨æ¸…ç† _temp_step_* ç›®å½•ï¼‰')
    parser.add_argument('--keep-chunked', action='store_true',
                       help='ä»…ä¿ç•™chunkæ­¥éª¤ä¹‹åçš„ä¸­é—´ç»“æœï¼ˆåˆ é™¤chunkä¹‹å‰çš„ä¸´æ—¶æ–‡ä»¶ï¼‰')
    parser.add_argument('--keep-penultimate', action='store_true',
                       help='ä»…ä¿ç•™å€’æ•°ç¬¬äºŒæ­¥ï¼ˆæœ€åä¸€æ­¥ä¹‹å‰ï¼‰çš„ä¸­é—´ç»“æœ')
    
    args = parser.parse_args()
    
    # æ£€æµ‹CPUæ ¸å¿ƒæ•°å¹¶ç»™å‡ºå»ºè®®
    cpu_count = mp.cpu_count()
    print(f"æ£€æµ‹åˆ° CPU æ ¸å¿ƒæ•°: {cpu_count}")
    if args.workers > cpu_count:
        print(f"è­¦å‘Š: æŒ‡å®šçš„å·¥ä½œçº¿ç¨‹æ•° ({args.workers}) è¶…è¿‡ CPU æ ¸å¿ƒæ•° ({cpu_count})")
    
    # è§£æå¤„ç†æ¨¡å¼ï¼ˆæ”¯æŒé€—å·åˆ†éš”çš„å¤šä¸ªæ¨¡å¼ï¼‰
    modes = [m.strip() for m in args.mode.split(',')]
    
    # éªŒè¯æ‰€æœ‰æ¨¡å¼éƒ½æ˜¯æœ‰æ•ˆçš„
    valid_modes = ['scale', 'crop', 'crop_rect', 'chunk', 'fisheye', 'enhance']
    for mode in modes:
        if mode not in valid_modes:
            print(f"é”™è¯¯: æ— æ•ˆçš„å¤„ç†æ¨¡å¼ '{mode}'")
            print(f"æœ‰æ•ˆæ¨¡å¼: {', '.join(valid_modes)}")
            return
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†æµæ°´çº¿: {' -> '.join(modes)}")
    print(f"{'='*60}\n")
    
    # è®¾ç½®åˆå§‹è¾“å…¥ç›®å½•
    current_source = args.source
    
    # æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªæ¨¡å¼
    for idx, mode in enumerate(modes):
        is_last_step = (idx == len(modes) - 1)
        # æ ¹æ®è¦æ±‚ï¼šç¬¬ä¸€æ­¥å’Œæœ€åä¸€æ­¥ä¸åˆ é™¤åŸè§†é¢‘æ–‡ä»¶ï¼Œä¸­é—´æ­¥åˆ™åœ¨å¤„ç†å®Œåç«‹å³åˆ é™¤
        is_first_step = (idx == 0)
        should_delete_input = not is_first_step and not is_last_step

        # ä¸ºä¸­é—´æ­¥éª¤åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        if is_last_step:
            current_output = args.output
        else:
            current_output = str(Path(args.output) / f"_temp_step_{idx}_{mode}")

        print(f"\n{'='*60}")
        print(f"æ­¥éª¤ {idx + 1}/{len(modes)}: {mode.upper()}")
        print(f"è¾“å…¥: {current_source}")
        print(f"è¾“å‡º: {current_output}")
        print(f"{'='*60}\n")
        
        if mode == 'scale':
            scale_videos_parallel(
                source_dir=current_source,
                output_dir=current_output,
                target_size=args.target_size,
                scale_factor=args.scale_factor,
                max_workers=args.workers,
                process_id=args.process_id,
                process_total=args.process_total,
                max_videos=args.max_videos,
                is_intermediate_step=should_delete_input
            )
        
        elif mode == 'crop':
            batch_resize_crop_videos(
                source_dir=current_source,
                output_dir=current_output,
                short_side_size=args.short_side,
                crop_size=args.crop_size,
                max_workers=args.workers,
                process_id=args.process_id,
                process_total=args.process_total,
                max_videos=args.max_videos,
                is_intermediate_step=should_delete_input
            )
        elif mode == 'crop_rect':
            # ä¸­å¿ƒçŸ©å½¢è£å‰ªï¼ˆä¸ç¼©æ”¾ï¼‰ï¼Œéœ€è¦ crop_width ä¸ crop_height
            if args.crop_width is None or args.crop_height is None:
                print("é”™è¯¯: ä½¿ç”¨ crop_rect æ¨¡å¼éœ€è¦æä¾› --crop-width ä¸ --crop-height")
                return
            # æ”¶é›†ä»»åŠ¡
            source_path = Path(current_source)
            output_path = Path(current_output)
            tasks = []
            for mp4_file in source_path.rglob("*.mp4"):
                if '/tmp/' in str(mp4_file):
                    continue
                relative_path = mp4_file.relative_to(source_path)
                output_file = output_path / relative_path
                tasks.append((mp4_file, output_file, args.crop_width, args.crop_height, should_delete_input))

            tasks.sort(key=lambda x: x[0].name)

            if args.process_id >= 0:
                tasks = tasks[args.process_id::args.process_total]
                print(f"Process {args.process_id}/{args.process_total}: assigned {len(tasks)} videos")

            print(f"Total videos to rect-crop: {len(tasks)}")
            if not tasks:
                print("No videos found to rect-crop")
            else:
                completed = 0
                with ProcessPoolExecutor(max_workers=args.workers) as executor:
                    with tqdm(total=len(tasks), desc="Rect Crop videos", unit="video") as pbar:
                        for result in executor.map(process_single_video_crop_rect, tasks):
                            completed += 1
                            pbar.set_postfix_str(result.split(':')[0] if ':' in result else result)
                            pbar.update(1)
        
        elif mode == 'chunk':
            chunk_videos_parallel(
                source_dir=current_source,
                output_dir=current_output,
                frames_per_chunk=args.frames_per_chunk,
                max_workers=args.workers,
                delete_original=args.delete_original or should_delete_input,
                process_id=args.process_id,
                process_total=args.process_total,
                max_videos=args.max_videos,
                is_intermediate_step=should_delete_input
            )
        
        elif mode == 'fisheye':
            fisheye_params = {
                'ih_fov': args.ih_fov,
                'iv_fov': args.iv_fov,
                'h_fov': args.h_fov,
                'v_fov': args.v_fov,
                'w': args.output_width,
                'h': args.output_height,
                'interp': args.interp
            }
            process_fisheye_videos(
                source_dir=current_source,
                output_dir=current_output,
                max_workers=args.workers,
                fisheye_params=fisheye_params,
                process_id=args.process_id,
                process_total=args.process_total,
                max_videos=args.max_videos,
                is_intermediate_step=should_delete_input
            )
        
        elif mode == 'enhance':
            enhance_params = {
                'denoise': args.denoise,
                'denoise_strength': args.denoise_strength,
                'sharpen': args.sharpen,
                'sharpen_strength': args.sharpen_strength,
                'contrast': args.enhance_contrast,
                'contrast_value': args.contrast_value,
                'brightness': args.brightness,
                'saturation': args.saturation
            }
            enhance_videos_parallel(
                source_dir=current_source,
                output_dir=current_output,
                max_workers=args.workers,
                enhance_params=enhance_params,
                process_id=args.process_id,
                process_total=args.process_total,
                max_videos=args.max_videos,
                is_intermediate_step=should_delete_input
            )
        
        # æ›´æ–°ä¸‹ä¸€æ­¥çš„è¾“å…¥ç›®å½•
        current_source = current_output
        
        print(f"\næ­¥éª¤ {idx + 1} å®Œæˆ!")
    
    # æ¸…ç†ä¸­é—´ä¸´æ—¶æ–‡ä»¶å¤¹
    if len(modes) > 1:
        if args.keep_penultimate:
            # åªä¿ç•™å€’æ•°ç¬¬äºŒæ­¥çš„ç»“æœ
            penultimate_idx = len(modes) - 2
            print(f"\n{'='*60}")
            print("ä¿ç•™å€’æ•°ç¬¬äºŒæ­¥çš„ä¸­é—´ç»“æœï¼Œæ¸…ç†å…¶ä»–ä¸´æ—¶æ–‡ä»¶ (--keep-penultimate)")
            print(f"{'='*60}\n")
            
            # åˆ é™¤å€’æ•°ç¬¬äºŒæ­¥ä¹‹å‰çš„æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
            for idx in range(penultimate_idx):
                temp_dir = Path(args.output) / f"_temp_step_{idx}_{modes[idx]}"
                if temp_dir.exists():
                    try:
                        shutil.rmtree(temp_dir)
                        print(f"âœ“ å·²åˆ é™¤: {temp_dir}")
                    except Exception as e:
                        print(f"âœ— åˆ é™¤å¤±è´¥ {temp_dir}: {e}")
            
            # ä¿ç•™å€’æ•°ç¬¬äºŒæ­¥
            penultimate_dir = Path(args.output) / f"_temp_step_{penultimate_idx}_{modes[penultimate_idx]}"
            if penultimate_dir.exists():
                print(f"ğŸ“ ä¿ç•™: {penultimate_dir}")
        
        elif args.keep_chunked:
            # æ‰¾åˆ°chunkæ­¥éª¤çš„ç´¢å¼•
            chunk_idx = None
            for idx, mode in enumerate(modes):
                if mode == 'chunk':
                    chunk_idx = idx
                    break
            
            if chunk_idx is not None:
                print(f"\n{'='*60}")
                print("ä¿ç•™chunkä¹‹åçš„ä¸­é—´ç»“æœï¼Œæ¸…ç†chunkä¹‹å‰çš„ä¸´æ—¶æ–‡ä»¶ (--keep-chunked)")
                print(f"{'='*60}\n")
                
                # åˆ é™¤chunkä¹‹å‰çš„æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                for idx in range(chunk_idx):
                    temp_dir = Path(args.output) / f"_temp_step_{idx}_{modes[idx]}"
                    if temp_dir.exists():
                        try:
                            shutil.rmtree(temp_dir)
                            print(f"âœ“ å·²åˆ é™¤: {temp_dir}")
                        except Exception as e:
                            print(f"âœ— åˆ é™¤å¤±è´¥ {temp_dir}: {e}")
                
                # ä¿ç•™chunkåŠä¹‹åçš„ä¸´æ—¶æ–‡ä»¶
                for idx in range(chunk_idx, len(modes) - 1):
                    temp_dir = Path(args.output) / f"_temp_step_{idx}_{modes[idx]}"
                    if temp_dir.exists():
                        print(f"ğŸ“ ä¿ç•™: {temp_dir}")
            else:
                print(f"\nâš ï¸  è­¦å‘Š: --keep-chunked éœ€è¦åœ¨å¤„ç†æ¨¡å¼ä¸­åŒ…å« 'chunk' æ­¥éª¤")
        
        elif not args.keep_intermediate:
            print(f"\n{'='*60}")
            print("æ¸…ç†ä¸­é—´ä¸´æ—¶æ–‡ä»¶...")
            print(f"{'='*60}\n")
            
            for idx in range(len(modes) - 1):
                temp_dir = Path(args.output) / f"_temp_step_{idx}_{modes[idx]}"
                if temp_dir.exists():
                    try:
                        shutil.rmtree(temp_dir)
                        print(f"âœ“ å·²åˆ é™¤: {temp_dir}")
                    except Exception as e:
                        print(f"âœ— åˆ é™¤å¤±è´¥ {temp_dir}: {e}")
        
        elif args.keep_intermediate:
            print(f"\n{'='*60}")
            print("ä¿ç•™ä¸­é—´ä¸´æ—¶æ–‡ä»¶ (--keep-intermediate)")
            print(f"{'='*60}\n")
            for idx in range(len(modes) - 1):
                temp_dir = Path(args.output) / f"_temp_step_{idx}_{modes[idx]}"
                if temp_dir.exists():
                    print(f"ğŸ“ ä¿ç•™: {temp_dir}")
    
    print(f"\n{'='*60}")
    print(f"âœ¨ æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼")
    print(f"æœ€ç»ˆè¾“å‡ºç›®å½•: {args.output}")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()

"""
python process_egocentric.py \
  --mode fisheye,scale,chunk,crop \
  --source example/exp/raw \
  --output example/exp/test33 \
  --ih-fov 105 --iv-fov 95 \
  --h-fov 95 --v-fov 90 \
  --output-width 910 --output-height 512 \
  --target-size 512 \
  --crop-size 256 \
  --frames-per-chunk 300 \
  --keep-chunked \
  --workers 16 
"""